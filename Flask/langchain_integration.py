# # langchain_integration.py
# # from langchain.llms import OpenAI

# # class LangChainHelper:
# #     def __init__(self, api_key):
# #         self.client = OpenAI(api_key=api_key)
    
# #     def predict_with_langchain(self, image_description):
# #         response = self.client.complete(prompt=image_description)
# #         return response
# # from langchain_community.llms import OpenAI  # Update the import statement
# # from langchain_openai import ChatOpenAI
# # from langchain_core.prompts import ChatPromptTemplate
# # from langchain_core.output_parsers import StrOutputParser


# # from langchain_openai import ChatOpenAI
# # llm = ChatOpenAI()



# class LangChainHelper:
#     # def __init__(self,input):
#     #     self.input = input
#         # self.client = OpenAI(api_key=api_key)
    
#     # def predict_with_langchain(self, image_description):
#     #     response = self.client.complete(prompt=image_description)
#     #     return response
#     # def predictUsinLangchain (str: input):
#     #     llm = ChatOpenAI(openai_api_key="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")
#     #     prompt = ChatPromptTemplate.from_messages([
#     #     ("system", "You a research assistant that that deals inn plan and diseaseresearch and "),
#     #     ("user", "{input}")
#     #     ])
#     #     output_parser = StrOutputParser()
#     #     chain = prompt | llm | output_parser
#     #     results  = chain.invoke({"input":input})
    
   
        
        





        
   



        